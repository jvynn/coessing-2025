{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b320b8c",
   "metadata": {},
   "source": [
    "## Introduction to Python for Physical Oceanography"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825c08ff",
   "metadata": {},
   "source": [
    "There are a lot of useful python tutorials out there, but few that really focus on the tools and types of workflows that are commonly employed when doing data analysis in physical oceanography ([this lecture](https://www.youtube.com/watch?v=ZyCkVI7k3eo) is a good exception). Here we'll go over some of the basic tools and how you might use them to load data, make figures, and do scientific analysis. More resources for learning python in general can be found [here](https://docs.python.org/3/tutorial/) and, for a more visual approach, [here](https://www.youtube.com/watch?v=rfscVS0vtbw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c06560",
   "metadata": {},
   "source": [
    "### Scientific Computing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90115258",
   "metadata": {},
   "source": [
    "Loading the ``numpy`` package is almost always a necessity when using Python for scientific computing. It contains essential mathematical functions in addition to those that enable efficient manipulation of large arrays and matrices, and support element-wise operations, broadcasting, linear algebra, Fourier transforms, and random number generation. If you're a MATLAB user, you'll notice that many of the functions that are native to MATLAB have been replicated in Python via ``numpy``. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f6ab9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53841f9b",
   "metadata": {},
   "source": [
    "In physical oceanography, we're often looking at processes that span large enough distances that we must account for the Earth's curvature. The haversine formula calculates the great-circle distance between two points on a sphere:\n",
    "\n",
    "$$\n",
    "a = \\sin^2\\left(\\frac{\\Delta\\phi}{2}\\right) + \\cos(\\phi_1)\\cos(\\phi_2)\\sin^2\\left(\\frac{\\Delta\\lambda}{2}\\right)\n",
    "$$\n",
    "\n",
    "$$\n",
    "c = 2 \\arcsin\\left( \\sqrt{a} \\right)\n",
    "$$\n",
    "\n",
    "$$\n",
    "d = R \\cdot c\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "- \\( $\\phi_1, \\phi_2$ \\) are the latitudes in radians  \n",
    "- $\\Delta\\phi = \\phi_2 - \\phi_1$ is the difference in latitude  \n",
    "- $\\Delta\\lambda = \\lambda_2 - \\lambda_1$ is the difference in longitude  \n",
    "- $R$ is Earth’s radius (≈ 6367 km)\n",
    "\n",
    "Here's how you would implement this formula with a Python function:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5dd770",
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine_np(coord1, coord2):\n",
    "    \"\"\"\n",
    "    Calculates the great-circle distance between two points \n",
    "    on the earth (specified in decimal degrees), given as (lat, lon) tuples.\n",
    "\n",
    "    Args:\n",
    "        coord1: tuple (lat1, lon1)\n",
    "        coord2: tuple (lat2, lon2)\n",
    "\n",
    "    Returns:\n",
    "        Distance in kilometers.\n",
    "    \"\"\"\n",
    "    lat1, lon1 = np.radians(coord1)\n",
    "    lat2, lon2 = np.radians(coord2)\n",
    "\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "\n",
    "    a = np.sin(dlat / 2.0) ** 2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2.0) ** 2\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    \n",
    "    km = 6367 * c  # Earth's radius in km\n",
    "    return km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0a022760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [LIVE CODE]: calculate the great-circle distance between Accra, Ghana and Woods Hole, MA, USA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf4a862",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b297478",
   "metadata": {},
   "source": [
    "In physical oceanography, we're often working with large datasets that are *geo-referenced* - arrays of physical variables like temperature and salinity in which each measurement has a latitude and longitude coordinate. Data structured this way is often packaged in \"NetCDF\" format (file extension \".nc\") and can be read by several python packages. One of the most commonly used is **[xarray](https://xarray.dev/)**, which is a great tool for manipulating data in stored in multidimensional arrays. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1b48d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7dcab5d",
   "metadata": {},
   "source": [
    "The data we're going to use in this workshop is hosted online at a series of URLs. Data can be directly downloaded from online servers using commands like ``wget``, which is a simple way to fetch files from the web using the command line. For example:\n",
    "```bash\n",
    "wget https://example.com/path/to/file.nc\n",
    "```\n",
    "This would download the file to your working directory. In this workshop, instead of doing a direct download we will simply *stream* the data. The URLs for all the NetCDFs are stored in the attached JSON file. (This is only slightly fancier than a plain text file in that it allows us to group like-files together, but a simple text file of URLs would also work fine). JSON files can be read with the follow command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2028bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"./data/data_manifest_January.json\", \"r\") as f:\n",
    "    manifest = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82234ef7",
   "metadata": {},
   "source": [
    "We can then loop through the urls in the manifest and open them in **xarray**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bb8b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fsspec # we need this to read the NetCDF files from URLs since xarray doesn't support reading from URLs directly\n",
    "\n",
    "# choose data type and optional density contour flag\n",
    "data_type = 'ctd'\n",
    "density_contour = False\n",
    "\n",
    "# load main datasets\n",
    "datasets = []\n",
    "for url in manifest.get(data_type, []):\n",
    "    with fsspec.open(url, mode='rb') as f:\n",
    "        ds = xr.open_dataset(f, decode_timedelta=True) # flag decode_timedelta=True to suppress warnings\n",
    "        datasets.append(ds)\n",
    "\n",
    "# load optional CTD datasets for density contour\n",
    "datasets_ctd = []\n",
    "if density_contour and data_type != 'ctd':\n",
    "    for url in manifest.get('ctd', []):\n",
    "        with fsspec.open(url, mode='rb') as f:\n",
    "            ds = xr.open_dataset(f, decode_timedelta=True)\n",
    "            datasets_ctd.append(ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a2f42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [LIVE CODE]: explore the datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c415b3",
   "metadata": {},
   "source": [
    "### Visualizing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa1cc0b",
   "metadata": {},
   "source": [
    "To visualize this data, we can use **matplotlib.pyplot**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b11d852",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6049e148",
   "metadata": {},
   "source": [
    "**xarray** does have a built in plotting function that is useful for visualizing data quickly, but notice that it doesn't give us much flexibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a246a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets[0].CT.plot(label='Temperature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23715f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [LIVE CODE]: plot a single profile temperature, salinity, chlorophyll, oxygen using matplotlib."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c9a257",
   "metadata": {},
   "source": [
    "### Geophysical Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320fd680",
   "metadata": {},
   "source": [
    "Often times in physical oceanography, we're interested in tracking the density of the water since it can tell us a lot about the dynamics. Density can be calculated from readily measured seawater properties like temperature and salinity since both impact seawater density: saltier water is more dense than fresh water and cold water is more dense than warm water. But what if seawater is warm but salty, or cold but fresh? \n",
    "\n",
    "The relative contribution of salinity and temperature to the observed seawater density is modeled by an **equation of state**, the simpliest of which is the linear equation:\n",
    "\n",
    "$$\n",
    "\\Delta \\rho = \\rho_0 (- \\alpha \\Delta T + \\beta \\Delta S)\n",
    "$$\n",
    "\n",
    "in which:\n",
    "- $\\rho$ is the seawater density (kg/m³)\n",
    "- $\\rho_0$ is a reference density (often around 1025 kg/m³)\n",
    "- $\\alpha$ is the **thermal expansion coefficient** (1/°C), and is always positive\n",
    "- $\\beta$ is the **haline contraction coefficient** (1/psu), also positive\n",
    "- $T$ is temperature (°C)\n",
    "- $S$ is salinity (psu)\n",
    "\n",
    "\n",
    "The international standard is a nonlinear polynomial with *many* terms and is implemented in full by the [Gibbs SeaWater (GSW) Toolbox of TEOS-10](https://teos-10.org/pubs/gsw/html/gsw_contents.html). We can use the [Python implementation](https://teos-10.github.io/GSW-Python/intro.html) here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695fc3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gsw\n",
    "# [LIVE CODE]: calculate potential density from conservative temperature and absolute salinity. \n",
    "# plot density\n",
    "# plot N^2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0244d101",
   "metadata": {},
   "source": [
    "Here's an example plotting function that combines all the tools we've used so far: basic scientific computing, oceanographic analysis, and data visualization techniques. It loops through each of the NetCDF files we've loaded in, and uses the gsw toolbox to calculate the potential density from the conservative temperature and absolute salinity, takes the mean and standard deviation across all profiles, and then plots them in 3 subplots. \n",
    "\n",
    "We have to import a custom function from `utils.py` that handles interpolation for data with NaNs (\"Not-a-Number\"s) since the code will otherwise throw an error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c085d466",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import * \n",
    "\n",
    "max_depth = 80\n",
    "depth_grid = np.linspace(10, max_depth, 50)  # define a common depth grid\n",
    "\n",
    "# initialize arrays to store interpolated values\n",
    "CT_interp = np.full((len(datasets), len(depth_grid)), np.nan)\n",
    "SA_interp = np.full((len(datasets), len(depth_grid)), np.nan)\n",
    "sigma_interp = np.full((len(datasets), len(depth_grid)), np.nan)\n",
    "\n",
    "# interpolate each profile onto the common depth grid\n",
    "for i, ds in enumerate(datasets):\n",
    "    p = ds[\"P\"].values\n",
    "    ct = ds[\"CT\"].values\n",
    "    sa = ds[\"SA\"].values\n",
    "    \n",
    "    p = interpolate_nans(p, np.arange(len(p)))\n",
    "    ct = interpolate_nans(ct, np.arange(len(ct)))\n",
    "    sa = interpolate_nans(sa, np.arange(len(sa)))\n",
    "    \n",
    "    # interpolate to the common depth grid\n",
    "    CT_interp[i, :] = np.interp(depth_grid, p, ct, left=np.nan, right=np.nan)\n",
    "    SA_interp[i, :] = np.interp(depth_grid, p, sa, left=np.nan, right=np.nan)\n",
    "\n",
    "    # compute potential density for each profile\n",
    "    sigma_interp[i, :] = gsw.density.sigma0(SA_interp[i, :], CT_interp[i, :])\n",
    "\n",
    "# compute the mean profile and std\n",
    "CT_mean = np.nanmean(CT_interp, axis=0)\n",
    "CT_std  = np.nanstd(CT_interp, axis=0)\n",
    "\n",
    "SA_mean = np.nanmean(SA_interp, axis=0)\n",
    "SA_std  = np.nanstd(SA_interp, axis=0)\n",
    "\n",
    "sigma_mean = np.nanmean(sigma_interp, axis=0)\n",
    "sigma_std  = np.nanstd(sigma_interp, axis=0)\n",
    "\n",
    "\n",
    "# create figure axes\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(7, 6))\n",
    "\n",
    "# plot mean profiles with variance visualized as shaded areas\n",
    "ax1.plot(CT_mean, depth_grid, 'b', linewidth=2, label=\"Mean\")\n",
    "ax1.fill_betweenx(depth_grid, CT_mean - CT_std, CT_mean + CT_std, color='b', alpha=0.2, linewidth=0)\n",
    "\n",
    "ax2.plot(SA_mean, depth_grid, 'r', linewidth=2, label=\"Mean\")\n",
    "ax2.fill_betweenx(depth_grid, SA_mean - SA_std, SA_mean + SA_std, color='r', alpha=0.2, linewidth=0)\n",
    "\n",
    "ax3.plot(sigma_mean, depth_grid, 'purple', linewidth=2, label=\"Mean\")\n",
    "ax3.fill_betweenx(depth_grid, sigma_mean - sigma_std, sigma_mean + sigma_std, color='purple', alpha=0.2, linewidth=0)\n",
    "\n",
    "\n",
    "# formatting axes\n",
    "ax1.set_ylabel('Pressure (dbar)') # 'Pressure (dbar)', 'Depth (m)'\n",
    "ax1.set_xlabel('Conservative Temperature (°C)')\n",
    "ax1.set_ylim(12, max_depth)\n",
    "ax1.set_xlim(15, 30)\n",
    "\n",
    "ax2.set_xlabel('Absolute Salinity (g/kg)')\n",
    "ax2.set_yticks([])\n",
    "ax2.set_ylim(12, max_depth)\n",
    "ax2.set_xlim(34.5, 36.5)\n",
    "\n",
    "ax3.set_xlabel('Potential Density (kg/m$^3$)')\n",
    "ax3.set_yticks([])\n",
    "ax3.set_ylim(12, max_depth)\n",
    "ax3.set_xlim(21, 28)\n",
    "\n",
    "ax1.invert_yaxis()\n",
    "ax2.invert_yaxis()\n",
    "ax3.invert_yaxis()\n",
    "\n",
    "fig.suptitle(f\"January Sakumono CTD Profiles (Average and Std Dev)\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27203198",
   "metadata": {},
   "source": [
    "Instead of looking at all of our data as a function of depth, sometimes it's useful to look at the data in \"temperature-salinity (T-S) space\". In this case, our $x$-axis is salinity, our $y$-axis is temperature, and each data point is plots with respect to both those properties. It can help us learn things about the source of our water, particularly since deep ocean water is formed in very specific places on Earth.\n",
    "\n",
    "Here's an example from some Argo float data (float 7580/WMO\\#3902237) collected off the coast of South America! \n",
    "\n",
    "![T-S_diagram](./figures/t-s-diagram.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ad9b86",
   "metadata": {},
   "source": [
    "Let's try to make a T-S diagram for the data from the data we've downloaded. Like in the previous figure, we'll need to declare our figure axes and then loop through each dataset to collect the temperature, salinity and temperature. There are many different ways to do it! \n",
    "\n",
    "Some useful functions are [``plt.scatter``](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.scatter.html) and [``plt.contour``](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.contour.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc4f08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a T-S diagram!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coessing-2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
